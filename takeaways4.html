<!DOCTYPE html>
<html lang="en">

<head>
<meta charset="utf-8" />
<link rel="stylesheet" href="https://dokie.li/media/css/lncs.css" />
<title>Takeaways for Week 4</title>
</head>

<body>

<h1>Takeaways for Week 4</h1>

<h2>Topics</h2>

<h3>Ontologies</h3>

<p class="counter">
Ontology evolved through philosophical questions, like the 'existence of god', and tries to organize the reality into its fundamental structures. The discipline helps to arrange the world around us and creates relationships between an entity and its actual meaning. Software engineering, in its basic principles, tries to map everyday concepts into software. To achieve this, it is essential that software models the entities in such a way that everyone has the same meaning. The difficulty for the latter is that software developers mostly do not work with one actual 'reference point'—one ontology. Concepts help to solve this issue. The three dimensions are used to describe concepts and transfer knowledge formally and digitally: a i) Symbol names the actual concept; the ii) Intension represents the semantic and meaning of the concept; and lastly the iii) Extension gives several examples for the concept. However, it is common that these concept specifications are incomplete and usually do not cover all possible circumstances.
</p>

<h3>Transparency within the General Data Protection Regulation</h3>

<p class="counter">
Since personal data become a valuable asset, especially for the so-called 'Big Five' (c.f. [Farhad 2017]), regulations about storing, retrieving, processing, and transferring personal data between one individual and companies become a crucial aspect. The General Data Protection Regulation (GDPR) was implemented in 2018 and is based on fundamental human rights to control how companies deal with data and privacy. Transparency is a key aspect within the GDPR and is the concept, e.g. how easily information on the GDPR is accessible to individuals or how comprehensible the regulations are composed from the companies. To get a better insight into how transparent these implementations are done by the companies and how they are applied, researchers are using knowledge organization techniques to map the official GDPR articles on the actual technical terms. Machine learning algorithms identifying key terms from the GDPR paragraphs and transform them into technical requirements. Tools are developed, like browser extensions, which use these technical representations to show the user how good or how bad the actual companies (i.e. the website) implements the GDPR and how transparent they are.
</p>

<h2>Literature</h2>

<h3 data-ranking="negative">Davis et al. 1993</h3>

<p class="counter">
In their study, the authors Davis, Shrobe, and Szolovits (1993) want to answer the question of what the actual meaning of knowledge representation is. The study delivered five different aspects with various parameters to describe knowledge representation. Each of these aspects requires the consideration of all other aspects and cannot stand alone. This holistic approach provides distinct perspectives on the topic and creates trade-offs among each other. One example is the consideration of the fourth and fifth role. In role four, knowledge representation is examined as a tool for structuring information so that reasonings can be computed by machines in respect of efficiency. If representations tend to be too much compatible with machine readability it poses a potential risk of creating useless representations for the actual end-user. Role five instead, expresses the actual mapping of the real world. The eventual language things are expressed into a machine-readable representation—is our actual language with all its disadvantages. Therefore, a machine can only compute reasonings which might be understandable for others but could also lead to misunderstandings. Davis et al. (1993) use the five roles also to define a framework to identify different kinds of representations.
</p>

<h3 data-ranking="neutral">Gruber 1995</h3>

<p class="counter">
In knowledge bases as well as in artificial intelligence, quality requirements as consistency and completeness are indispensable [Gruber 1995, Rashid et al. 2019]. It is not common that one base or one agent is capable of answering all questions on its own. Therefore, the knowledge bases or agents respectively, are distributed beyond network borders to achieve completeness. Gruber (1995) proposed the need for shared ontologies in order to reach agreement on a vocabulary that can be used interchangeably—and to achieve consistency. For creating such formal ontologies, the author provides a set of prerequisites on how to design shared ontologies. It is crucial, among other aspects, that the ontology can grow according to the actual needs over time without the interference of the existing vocabulary. As important as in several other areas, the need for human-friendly documentation is essential as well. However, these concepts are trade-offs among each other. Therefore, Gruber provides several case studies that clarify that the criteria are only the base for the design process and that the process is in a correlation with the available knowledge itself.
</p>

<h3 data-ranking="positive">Horrocks 2008</h3>

<p class="counter">
Ontology can be considered from the philosophical aspect, but also from the software technical viewpoint. Latter describes the science of modeling the world with all its entities into software by using a common vocabulary [Horrocks 2008]. The concept of (software) ontologies plays an important role when it comes to knowledge-representation and agents in combination with the World Wide Web. A semantic representation of the web is not enough to compute reasoning and relations behind an actual formal representation. The Web Ontology Language (OWL) tries to solve this problem. OWL has its nature in description logic and comes along with all its logic-based formalism. OWL offers i) quantifiers from first order-logic (i.e. existential and universal), ii) boolean conjunctions, iii) cardinality restrictions, and iv) "if-else" axioms. Horrocks (2008) compares OWL with databases in such a sense that OWL achieves reasoning together with the actual data. However, databases are more strict concerning constraint violations for, e.g., missing entries. OWL ontologies can become complex which makes it inefficient and difficult to maintain as well as to debug. Several tools are developed by different industry sectors to handle this kind of complexity and improve the adoption of OWL ontologies. 
</p>

<h3 data-ranking="positive">Heath and Bizer 2011</h3>

<p class="counter">
Together with the increasing number of websites and their corresponding data they provide, new product lines appear [Heath and Bizer 2011]. Companies either collect data from different websites (or try to reach almost the entire web universe) and provide them as a single source; or companies offer their services and data beyond their ecosystem. To achieve both, it is crucial that data can be re-used and follow a structured concept. WebAPIs offers data access via an endpoint where clients can run queries and requests. In most cases, the response of such requests is formed as structured XML or JSON data. However, these requests are most worthwhile in their ecosystem. The Resource Description Framework (RDF) tries to solve this in such a way, as entities are related to each other to achieve relationships between resources—'things'. Instead of simply referring to other sources via hyperlinks, RDF describes how the linked source is related to the current one. This enables a traversable web. Heath and Bizer (2011) believe, if the adoption of this 'Linked Data' principle would increase, the actual web would transform to the 'Web of Data', which enables a relationship between all available data.
</p>

<h2>References</h2>

<ul>
<li>Davis, Shrobe, and Szolovits. 1993. <a href="http://dx.doi.org/10.1609/aimag.v14i1.1029">What is a Knowledge Representation?</a> AI magazine, 14(1).</li>
<li>Gruber. 1995. <a href="http://dx.doi.org/10.1006/ijhc.1995.1081">Toward principles for the design of ontologies used for knowledge sharing.</a> International Journal of Human-Computer Studies, 43(5-6).</li>
<li>Horrocks. 2008. <a href="http://dx.doi.org/10.1145/1409360.1409377">Ontologies and the Semantic Web.</a> Communications of the ACM, 51(12). </li>
<li>Heath and Bizer. 2011. <a href="http://dx.doi.org/10.2200/S00334ED1V01Y201102WBE001">Chapter 1 of Linked Data: Evolving the Web into a Global Data Space.</a> Synthesis Lectures on the Semantic Web: Theory and Technology, 1:1, 1-136. Morgan & Claypool.</li>
<li>Farhad. 2017. <a href="https://www.nytimes.com/2017/11/01/technology/five-tech-giants-upside.html">The Upside of Being Ruled by the Five Tech Giants.</a> The New York Times.</li>
<li>Rashid, Rizzo, Torchiano, Mihindukulasooriya, Corcho, and García-Castro. 2019. <a href="https://doi.org/10.1016/j.websem.2018.11.004">Completeness and consistency analysis for evolving knowledge bases.</a> Journal of Web Semantics, 54, 48-71.</li>
</ul>

<script src="https://raw.githack.com/ucds-vu/ko2020-portfolio-template/master/scripts.js"></script>

</body>
</html>

